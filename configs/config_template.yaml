random_seed: 0b011011
run_name: "exp2_sbr"
## downsample ratio is modified

#-----------------------------------------------
#1. Dataset
#-----------------------------------------------

dataset:
  # ratio: 0.0005
  ratio: 1
  wb_train: [
              "/home/woongjib/Projects/Dataset_Crop/Splits/GT/FSD50K",
              "/home/woongjib/Projects/Dataset_Crop/Splits/GT/MUSDB18",
              "/home/woongjib/Projects/Dataset_Crop/Splits/GT/VCTK",
              ]
  nb_train: [
              "/home/woongjib/Projects/Dataset_Crop/Splits/SBR_20_Core/FSD50K",
              "/home/woongjib/Projects/Dataset_Crop/Splits/SBR_20_Core/MUSDB18",
              "/home/woongjib/Projects/Dataset_Crop/Splits/SBR_20_Core/VCTK",
              ]  
  wb_test: [
              "/home/woongjib/Projects/USAC/USAC44_GT", 
              ]
  nb_test: [
              "/home/woongjib/Projects/USAC/USAC44_20_core", 
              ]

  batch_size: 16
  seg_len: 0.9
  num_workers: 4
  start_index: 6 # num cores
 
#-----------------------------------------------
#2. Model
#-----------------------------------------------

generator:
  type: MBSEANet_film
  in_channels: 64 #FE
  min_dim: 32     #SEANet 56?
  visualize: False
  c_in: 6
  c_out: 26
  strides: [1,2,2,2]
  subband_num: 26
  fe_weight_path: False
  out_bias: False

discriminator: 
  # activate of deactivate either discriminators
  MultiBandSTFTDiscriminator_config:
      C: 32
      n_fft_list: [2048, 1024, 512]
      hop_len_list: [512, 256, 128]
      band_split_ratio:
          - [0.1875, 0.35] # check only 4.5 kHz above
          - [0.35, 0.5125] # 0.1 -> 0.1875
          - [0.5125, 0.675]
          - [0.675, 0.8375]
          - [0.8375, 1.0]

  PeriodDiscriminator_config:
      period_list: [2,3,5,7,11]
      C_period: 24

#-----------------------------------------------
#3. Loss
#-----------------------------------------------
loss:
  ms_mel_loss_config:
            n_fft_list: [32, 64, 128, 256, 512, 1024, 2048]
            hop_ratio: 0.25
            mel_bin_list: [5, 10, 20, 40, 80, 160, 320]
            reduction: mean
            loss_ratio: 1.0
            sr: 48000
            fmin: 0
            core_cutoff: 4500

  lambda_mel_loss: 15
  lambda_fm_loss: 2
  lambda_adv_loss: 1
  lambda_commitment_loss: 0.25 # only for RVQ models
  lambda_codebook_loss: 1
  lambda_subband_loss: 0


#-----------------------------------------------
#4. Optimizer (ADAM)
#-----------------------------------------------
optim:
  learning_rate_ft: 0.0001
  learning_rate: 1.0e-4
  scheduler_gamma: 0.999997
  B1: 0.5
  B2: 0.9
  
use_tri_stage:
  False
# tri_scheduler:
#   # for tri-tage
#   init_lr: 1.0e-6
#   final_lr: 1.0e-4
#   peak_lr: 1.0e-6
#   warmup_steps: 10000
#   hold_steps: 300000
#   decay_steps: 190000
#   total_steps: 500000

#-----------------------------------------------
#Training
#-----------------------------------------------
train:
  val_step: 2500 # 180ë¶„ 10000 step
  pretrain_step: False # else False
  ckpt_save_dir: "./ckpts/exp_temp"
  max_epochs: 40

  # True if load from previous
  ckpt: False
  ckpt_path: "/home/woongzip/mbseanet/ckpts/P4EXP1_crop88/step_0.7k_lsdh_2.4142.pth"

eval:
  eval_dir_audio: "/home/woongjib/Projects/BESSL__/outputs/P4EXP16_audio"
  eval_dir_speech: "/home/woongjib/Projects/BESSL__/outputs/P4EXP16_speech"
